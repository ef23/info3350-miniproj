{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering, normalization, weighting functions\n",
    "\n",
    "We have been working on ways to represent a collection of documents as a matrix. So far we have looked at classification and two-dimensional projections. What else can we do with such a matrix?\n",
    "\n",
    "In today's class we will try a new tool, clustering, and measure how properties of our input matrix affect the output of clustering algorithms.\n",
    "\n",
    "We will consider three modifications:\n",
    "\n",
    "1. Normalization for length of documents\n",
    "2. Inverse Document Frequency weighting of words\n",
    "3. Changes in vocabulary\n",
    "\n",
    "In every case, we should always look for the possiblity of errors. Is the algorithm finding patterns in data, or artifacts of our curation process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response:\n",
    "\n",
    "Describe the effect of length, word weighting, and vocabulary choices on clustering. Provide specific examples of output. Compare your results to the results of others at your table. Do you see consistent results? Describe any similarities or differences.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, sys, os, re\n",
    "from collections import Counter\n",
    "import numpy\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "\n",
    "word_pattern = re.compile(\"\\w[\\w\\-\\']*\\w|\\w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "with open(\"../data/Gutenberg-2019-10-21/metadata.csv\", encoding=\"utf-8\") as reader:\n",
    "    csv_reader = csv.DictReader(reader)\n",
    "    for document in csv_reader:\n",
    "        try:\n",
    "            with open(\"../data/Gutenberg-2019-10-21/{}\".format(document[\"Filename\"]), encoding=\"utf-8\") as reader:\n",
    "                print(document[\"Author\"] + \" / \" + document[\"Title\"])\n",
    "\n",
    "                lines = []\n",
    "                for line in reader:\n",
    "                    lines.append(line.rstrip())\n",
    "\n",
    "                text = \" \".join(lines)\n",
    "                document[\"Text\"] = text\n",
    "                document[\"Tokens\"] = word_pattern.findall(text)\n",
    "                \n",
    "                documents.append(document)\n",
    "        except Exception as e:\n",
    "            print(\"! Problem with {}: {}\".format(document[\"Filename\"], e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts = Counter()\n",
    "\n",
    "for document in documents:\n",
    "    doc_counter = Counter(document[\"Tokens\"])\n",
    "    all_counts += doc_counter   \n",
    "    document[\"TokenCounts\"] = doc_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter([doc[\"Author\"] for doc in documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a fixed vocabulary\n",
    "\n",
    "vocabulary = [w for w, c in all_counts.most_common()]\n",
    "\n",
    "### This might be a good place to select subsets of the vocabulary\n",
    "\n",
    "vocabulary_size = len(vocabulary)\n",
    "reverse_vocab = { w: i for i, w in enumerate(vocabulary) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter_to_vector(counter):\n",
    "    vector = numpy.zeros(vocabulary_size)\n",
    "    for word in counter.keys():\n",
    "        ## look up the integer ID for the string *if* it has one\n",
    "        if word in reverse_vocab:\n",
    "            word_id = reverse_vocab[word]\n",
    "            vector[word_id] = counter[word]\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert counters to vectors\n",
    "doc_word_matrix = numpy.zeros( (len(documents), len(vocabulary)) )\n",
    "\n",
    "for doc_id, document in enumerate(documents):\n",
    "    doc_word_matrix[doc_id,:] = counter_to_vector(document[\"TokenCounts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_weights = numpy.zeros(len(vocabulary))\n",
    "\n",
    "for word_id, word in enumerate(vocabulary):\n",
    "    docs_with_word = len(numpy.nonzero(doc_word_matrix[:,word_id])[0])\n",
    "    idf_weights[word_id] = numpy.log( (1 + len(documents)) / docs_with_word )\n",
    "    \n",
    "for word_id in range(20):\n",
    "    print(vocabulary[word_id], idf_weights[word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply each column by the IDF weight for that word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_norms = numpy.linalg.norm(doc_word_matrix, axis=1)\n",
    "print(sorted(zip(doc_norms, [doc[\"Title\"] for doc in documents]), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide each row by the norm of that document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 12\n",
    "\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "kmeans.fit(doc_word_matrix)\n",
    "clusters = kmeans.labels_\n",
    "\n",
    "pyplot.hist(clusters)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = numpy.array([\"{}\".format(doc[\"Author\"]) for doc in documents])\n",
    "short_names = numpy.array([\"{} / {}\".format(doc[\"Author\"], doc[\"Title\"]) for doc in documents])\n",
    "\n",
    "for cluster in range(num_clusters):\n",
    "    print(Counter(authors[ clusters == cluster ]))\n",
    "    print(short_names[clusters == cluster])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = numpy.array([int(doc[\"Year\"]) for doc in documents])\n",
    "pyplot.scatter(years, clusters)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section shows information about the \"mean\" of each of the $K$ clusters. Use this output to get ideas about how to modify the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in range(num_clusters):\n",
    "    ## get the vector for the cluster mean\n",
    "    word_weights = kmeans.cluster_centers_[cluster,:] # row for cluster, all columns\n",
    "    ## sort the vocabulary by those mean values\n",
    "    sorted_words = sorted(zip(word_weights, vocabulary), reverse=True)\n",
    "    ## print the cluster number and then top twenty words, showing word and mean\n",
    "    print(cluster, \" \".join([\"{} ({:.2f})\".format(w, s) for s, w in sorted_words[:20]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
