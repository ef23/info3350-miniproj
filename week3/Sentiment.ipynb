{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3, part 1: Build your own emotion lexicon\n",
    "\n",
    "Can we use word counts to measure emotion? And can we go beyond simple positive/negative \"valence\"?\n",
    "\n",
    "Last week we looked at pre-built sentiment lexicons. Today we will work in groups to define your own lexicons for specific emotions.\n",
    "\n",
    "[Robert Plutchik](https://en.wikipedia.org/wiki/Robert_Plutchik) defines eight basic [emotions](https://en.wikipedia.org/wiki/Emotion): joy/sadness, anticipation/surprise, trust/disgust, anger/fear.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "\n",
    "Work with the other students at your table. You will turn in a single report to CMS. All students in a group will get the same grade, so make sure everyone participates.\n",
    "\n",
    "1. Create a shared spreadsheet doc, such as Google sheets. You can download these files in CSV format from the File / Download / ... menu option. Create a second shared document to record your notes.\n",
    "\n",
    "1. Create a group in CMS\n",
    "\n",
    "1. I've added a new optional argument to `score_counts` and `load_paragraphs`: `extra_words`. Discuss what this option does, and try a few different numbers using the default lexicon (`bingliu`) and novel (`christmas`). In your document, describe your findings.\n",
    "\n",
    "1. Choose an emotion or opposed pair of emotions. Plutchik's are a good start, but feel free to try others.\n",
    "\n",
    "1. Brainstorm words that you think indicate this emotion. Put numeric weights in the first column and words in the second column, as we did for the file `bingliu.csv`.\n",
    "\n",
    "1. Download your lexicon, and change the filename for `load_word_weights` to that filename. Save this file as \"Version 1\", and keep a copy of it.\n",
    "\n",
    "1. Apply the lexicon to Dickens novels. Each student should choose one of the files in the `dickens` directory. Change the filename passed to `load_paragraphs` appropriately.\n",
    "\n",
    "1. Discuss your results. Compare top- and bottom- scoring paragraphs in the different novels. Look at the raw and \"rolling mean\" time series. Find passages that score high and low in these time series and look at the context around those paragraphs. In your document, copy in example paragraphs and comment on whether they are correct or not correct, and why. Each student should contribute, put your name on your exma\n",
    "\n",
    "1. Based on the results of your initial lexicon, create \"Version 2\" of your spreadsheet. Add or remove words, and change weights as necessary.\n",
    "\n",
    "1. Save this Version 2 lexicon as a CSV, and repeat the previous exploration. Document all of your findings in the shared document.\n",
    "\n",
    "1. Reflection. We will compare and discuss results in class. After that, write responses to the following in your document. Does your lexicon work? Was this process difficult? What factors made it easy or hard? Was your emotion easier or harder than others? If any other group worked on the same emotion, did they get similar results?\n",
    "\n",
    "1. Upload a zip file containing your written document and CSV copies of all versions of your sentiment lexicon files to CMS. Each member will need to join the CMS group to receive credit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, sys\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot\n",
    "import numpy, pandas\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDEAS FOR YOUR WRITING RESPONSE FOR FRIDAY:\n",
    "\n",
    " Both groups are working from Vonnegut's description of plot. Does this\n",
    "  view really reflect plot? If not, what is missing, and how important is it\n",
    "  to you?\n",
    "\n",
    " Given your experience with lexicon-based sentiment analysis, how well does\n",
    "  it approximate a quantity that's relevant for plot analysis?\n",
    "\n",
    " Would a more nuanced view of emotion lead to a better representation of plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_word_weights(lexicon_file):\n",
    "\n",
    "    ## Create a mapping from words to numbers\n",
    "    word_weights = {}\n",
    "    with open(lexicon_file) as lexicon_reader:\n",
    "        for line in lexicon_reader:\n",
    "            weight, word = line.rstrip().split(\",\") ## split on comma\n",
    "            word_weights[word] = float(weight) ## convert string to number\n",
    "    \n",
    "    return word_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This function applies the word weights to a list of word counts\n",
    "def score_counts(counter, word_weights, extra_words = 0):\n",
    "    ## accumulate word weights in this variable\n",
    "    score = 0\n",
    "    \n",
    "    ## count the words in the passage\n",
    "    total_tokens = sum(counter.values())\n",
    "    ## check for empty segments\n",
    "    if total_tokens == 0:\n",
    "        return 0\n",
    "    \n",
    "    ## for each word, look up its score\n",
    "    for word in counter.keys():\n",
    "        if word in word_weights:\n",
    "            score += word_weights[word] * counter[word]\n",
    "    return score / (total_tokens + extra_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_paragraphs(text_file, extra_words = 0):\n",
    "\n",
    "    ## Here's an example of a simple pattern defining a word token. \n",
    "    word_pattern = re.compile(\"\\w[\\w\\-\\']*\\w|\\w\") ## what matches this?\n",
    "\n",
    "    ## Now look at the actual documents. We'll create a list with one object per text segment.\n",
    "    paragraphs = []\n",
    "    \n",
    "    ## here's where we actually read the file\n",
    "    with open(text_file, encoding=\"utf-8\") as file:\n",
    "    \n",
    "        ## This block reads a file line by line.\n",
    "        for line in file:\n",
    "            line = line.rstrip()\n",
    "        \n",
    "            tokens = word_pattern.findall(line)\n",
    "        \n",
    "            ## turn a list into a word->count map\n",
    "            paragraph_counts = Counter(tokens)\n",
    "        \n",
    "            ## create the paragraph object, with the original text, \n",
    "            ##  the word counts, and the total score.\n",
    "            paragraphs.append({'text': line, 'counts': paragraph_counts,\n",
    "                               'score': score_counts(paragraph_counts, word_weights, extra_words) })\n",
    "\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODIFY THESE TWO FILENAMES\n",
    "\n",
    "word_weights = load_word_weights(\"bingliu.csv\")\n",
    "paragraphs = load_paragraphs(\"dickens/christmas.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_paragraphs = sorted(paragraphs, key=lambda x: x[\"score\"])\n",
    "\n",
    "## Display the 10 most negative\n",
    "for paragraph in sorted_paragraphs[0:9]:\n",
    "    print(\"{}\\t{}\".format(paragraph['score'], paragraph['text']))\n",
    "\n",
    "## ... and the 10 most positive\n",
    "for paragraph in sorted_paragraphs[-10:-1]:\n",
    "    print(\"{}\\t{}\".format(paragraph['score'], paragraph['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this block to show a timeseries of raw scores\n",
    "\n",
    "sentiment_scores = numpy.array([p[\"score\"] for p in paragraphs])\n",
    "\n",
    "pyplot.figure(figsize=(20, 5))\n",
    "pyplot.plot(sentiment_scores)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_mean = pandas.Series(sentiment_scores).rolling(20).mean()\n",
    "\n",
    "pyplot.figure(figsize=(20, 5))\n",
    "pyplot.plot(rolling_mean)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use this block to look at specific paragraphs\n",
    "\n",
    "for p in paragraphs[600:630]:\n",
    "    print(f\"{p['score']:.2f}\\t{p['text']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
