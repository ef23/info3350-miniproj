{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author attribution project wrap up\n",
    "\n",
    "In this class we'll complete our mini-project on the Federalist Papers and authorship attribution. We will cover the singular value decomposition (SVD) and how it gives us the ability to visualize differences. We will look at the comparison of cosine similarities for each individual document of uncertain authorship.\n",
    "\n",
    "You will *not* have to turn in this notebook, but it will be useful in completing the previous notebooks, especially last Wednesday's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, sys, os\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import numpy\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have updated the metadata file to include Federalist 74. If you have edited the metadata file there may be a merge conflict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "###                                      note name change â†“ \n",
    "with open(\"../data/FederalistPapers/metadata_federalist_fixed.csv\", encoding=\"utf-8\") as reader:\n",
    "    csv_reader = csv.DictReader(reader)\n",
    "    for row in csv_reader:\n",
    "        ## convert string to int\n",
    "        row[\"Number\"] = int(row[\"Number\"])\n",
    "        row[\"Filename\"] = \"../data/FederalistPapers/federalist_{:02d}.txt\".format(row[\"Number\"])\n",
    "        if os.path.exists(row[\"Filename\"]):\n",
    "            documents.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in documents:\n",
    "    try:\n",
    "        with open(document[\"Filename\"], encoding=\"utf-8\") as reader:\n",
    "            print(document[\"Number\"], document[\"Author\"], document[\"Title\"])\n",
    "\n",
    "            lines = []\n",
    "            for line in reader:\n",
    "                lines.append(line.rstrip())\n",
    "\n",
    "            text = \" \".join(lines)\n",
    "            document[\"Spacy\"] = nlp(text)\n",
    "    except:\n",
    "        print(\"Problem with {}\".format(document[\"Number\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts = Counter()\n",
    "\n",
    "for document in documents:\n",
    "    doc_counter = Counter([token.text for token in document[\"Spacy\"]])\n",
    "    all_counts += doc_counter   \n",
    "    document[\"TokenCounts\"] = doc_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our representation of documents\n",
    "\n",
    "How many words should we consider when doing similarity comparisons? Be ready to rerun the following cell with differing values of `num_top_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_words = 150\n",
    "top_words = [w for w, c in all_counts.most_common(num_top_words)]\n",
    "\n",
    "doc_word_counts = numpy.zeros( (len(documents), num_top_words) )\n",
    "\n",
    "for doc_id, document in enumerate(documents):\n",
    "    for word_id, word in enumerate(top_words):\n",
    "        doc_word_counts[doc_id,word_id] = document[\"TokenCounts\"][word]\n",
    "\n",
    "doc_lengths = doc_word_counts.sum(axis=1)\n",
    "\n",
    "doc_word_probs = doc_word_counts / doc_lengths[:,numpy.newaxis]\n",
    "\n",
    "word_means = doc_word_probs.mean(axis=0)\n",
    "word_sds = doc_word_probs.std(axis=0)\n",
    "\n",
    "doc_word_zscores = (doc_word_probs - word_means[numpy.newaxis,:]) / word_sds[numpy.newaxis,:]  ## subtract means, divide by std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U,S,Vt = numpy.linalg.svd(doc_word_zscores, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(14, 8))\n",
    "pyplot.yticks([])\n",
    "pyplot.xticks(range(75), top_words[:75], rotation=\"vertical\")\n",
    "pyplot.imshow(Vt[:5,:75])\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_list = numpy.array([doc[\"Author\"] for doc in documents])\n",
    "\n",
    "pyplot.figure(figsize=(14, 14))\n",
    "pyplot.xticks([])\n",
    "pyplot.yticks(range(len(author_list)), author_list)\n",
    "pyplot.imshow(U[:,:5])\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = {\"Alexander Hamilton\": \"red\", \"James Madison\": \"blue\",\n",
    "            \"John Jay\": \"green\", \"Alexander Hamilton and James Madison\": \"purple\",\n",
    "            \"Alexander Hamilton or James Madison\": \"gray\",}\n",
    "\n",
    "authors = [colormap[doc[\"Author\"]] for doc in documents]\n",
    "\n",
    "def show_2d(dimension1, dimension2):\n",
    "    pyplot.figure(figsize=(8,8))\n",
    "    pyplot.scatter(U[:,dimension1], U[:,dimension2], c=authors)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_2d(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-class exercise: Attribute a document\n",
    "\n",
    "Each table should \"adopt\" one document of unknown authorship. Use the `nearest` function to find the closest documents, and be ready to report the authors of the five closest documents *not including* the document itself. \n",
    "\n",
    "Do the same for one document of unknown authorship.\n",
    "\n",
    "Vary the number of top words. Do the closest authors change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Python arrays start with 0, but the\n",
    "##  Federalist Papers start at 1, and some are missing.\n",
    "## This list comprehension will give us the list indexes\n",
    "##  for the documents of uncertain authorship.\n",
    "\n",
    "[(i, doc[\"Number\"]) for i, doc in enumerate(documents)\n",
    " if doc[\"Author\"] == \"Alexander Hamilton or James Madison\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula for cosine similarity is\n",
    "\n",
    "$$cos(x, y) = \\frac{x^T y}{\\|x\\|\\|y\\|}$$\n",
    "\n",
    "$\\|x\\|$ is the *norm* of $x$, which is also its length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = [\"{} {}, {}\".format(doc[\"Number\"], doc[\"Author\"], doc[\"Title\"][:30]) for i, doc in enumerate(documents)]\n",
    "\n",
    "zscore_norms = numpy.linalg.norm(doc_word_zscores, axis=1)\n",
    "\n",
    "def nearest(query_id):\n",
    "    dot_products = doc_word_zscores.dot(doc_word_zscores[query_id,:])\n",
    "    \n",
    "    normalizers = zscore_norms * zscore_norms[query_id]\n",
    "    \n",
    "    cosines = dot_products / normalizers\n",
    "    \n",
    "    for comparison in sorted(zip(cosines, descriptors), reverse=True):\n",
    "        print(\"{:.2f} {}\".format(comparison[0], comparison[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest(52)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
